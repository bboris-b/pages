<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Meeting Transcript Tool</title>
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lucide-react/0.263.1/umd/lucide-react.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { 
            margin: 0; 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;
        const { Mic, MicOff, Play, Pause, Users, FileText, Brain, Settings, Download, Copy } = lucideReact;

        const LiveTranscriptionTool = () => {
          const [isRecording, setIsRecording] = useState(false);
          const [activeTab, setActiveTab] = useState('transcript');
          const [meetingFormat, setMeetingFormat] = useState('general');
          const [language, setLanguage] = useState('it-IT');
          const [transcript, setTranscript] = useState([]);
          const [notes, setNotes] = useState('');
          const [summary, setSummary] = useState('');
          const [currentSpeaker, setCurrentSpeaker] = useState('Speaker 1');
          const [speakerCount, setSpeakerCount] = useState(1);
          const [isGeneratingSummary, setIsGeneratingSummary] = useState(false);
          
          const recognitionRef = useRef(null);
          const silenceTimerRef = useRef(null);
          const lastSpeechTimeRef = useRef(Date.now());

          const meetingFormats = {
            general: 'Meeting Generale',
            sales: 'Sales Call',
            standup: 'Daily Standup',
            team: 'Team Meeting',
            interview: 'Colloquio'
          };

          const languages = {
            'it-IT': 'Italiano',
            'en-US': 'English (US)',
            'en-GB': 'English (UK)'
          };

          // Inizializza Web Speech API
          useEffect(() => {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
              const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
              recognitionRef.current = new SpeechRecognition();
              
              const recognition = recognitionRef.current;
              recognition.continuous = true;
              recognition.interimResults = true;
              recognition.lang = language;
              
              recognition.onresult = (event) => {
                let finalTranscript = '';
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                  const transcript = event.results[i][0].transcript;
                  if (event.results[i].isFinal) {
                    finalTranscript += transcript;
                  } else {
                    interimTranscript += transcript;
                  }
                }
                
                if (finalTranscript) {
                  const now = new Date();
                  const timeString = now.toLocaleTimeString('it-IT', { 
                    hour: '2-digit', 
                    minute: '2-digit' 
                  });
                  
                  // Rileva cambio speaker basato su pause lunghe
                  const timeSinceLastSpeech = Date.now() - lastSpeechTimeRef.current;
                  if (timeSinceLastSpeech > 3000) { // 3 secondi di pausa
                    detectSpeakerChange();
                  }
                  lastSpeechTimeRef.current = Date.now();
                  
                  setTranscript(prev => [...prev, {
                    id: Date.now(),
                    speaker: currentSpeaker,
                    text: finalTranscript.trim(),
                    timestamp: timeString,
                    language: detectLanguage(finalTranscript)
                  }]);
                }
              };
              
              recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
              };
              
              recognition.onend = () => {
                if (isRecording) {
                  recognition.start(); // Riavvia se dovrebbe essere ancora attivo
                }
              };
            }
          }, [language, currentSpeaker, isRecording]);

          // Rileva cambio di lingua nel testo
          const detectLanguage = (text) => {
            const italianWords = ['e', 'di', 'che', 'il', 'la', 'per', 'con', 'sono', 'una', 'del'];
            const englishWords = ['the', 'and', 'is', 'in', 'to', 'of', 'a', 'that', 'it', 'with'];
            
            const words = text.toLowerCase().split(' ');
            const italianCount = words.filter(word => italianWords.includes(word)).length;
            const englishCount = words.filter(word => englishWords.includes(word)).length;
            
            return italianCount > englishCount ? 'IT' : 'EN';
          };

          // Rileva cambio speaker
          const detectSpeakerChange = () => {
            // Logica semplificata: alterna tra speaker
            const speakerNumber = (parseInt(currentSpeaker.split(' ')[1]) % speakerCount) + 1;
            setCurrentSpeaker(`Speaker ${speakerNumber}`);
          };

          // Avvia/ferma registrazione
          const toggleRecording = async () => {
            if (!recognitionRef.current) {
              alert('Speech Recognition non supportato in questo browser. Usa Chrome o Edge.');
              return;
            }

            try {
              if (!isRecording) {
                // Richiedi permesso microfono
                await navigator.mediaDevices.getUserMedia({ audio: true });
                recognitionRef.current.lang = language;
                recognitionRef.current.start();
                setIsRecording(true);
              } else {
                recognitionRef.current.stop();
                setIsRecording(false);
                generateSummary();
              }
            } catch (error) {
              console.error('Errore accesso microfono:', error);
              alert('Errore: impossibile accedere al microfono. Controlla i permessi del browser.');
            }
          };

          // Genera riassunto AI
          const generateSummary = async () => {
            if (transcript.length === 0) return;
            
            setIsGeneratingSummary(true);
            
            try {
              const transcriptText = transcript.map(t => `${t.speaker} (${t.timestamp}): ${t.text}`).join('\n');
              
              const prompt = `Analizza questa trascrizione di meeting e crea un riassunto strutturato in italiano:

TRASCRIZIONE:
${transcriptText}

NOTE COLLABORATIVE:
${notes}

FORMATO MEETING: ${meetingFormats[meetingFormat]}

Crea un riassunto strutturato con:
1. **Punti Salienti** (max 5 punti principali)
2. **Decisioni Prese** (se presenti)
3. **Action Items** (con responsabili se identificabili)
4. **Prossimi Passi**
5. **Follow-up Necessari**

Usa un tono professionale ma accessibile. Se ci sono elementi in inglese, traducili in italiano.`;

              const response = await fetch("https://api.anthropic.com/v1/messages", {
                method: "POST",
                headers: {
                  "Content-Type": "application/json",
                },
                body: JSON.stringify({
                  model: "claude-sonnet-4-20250514",
                  max_tokens: 1500,
                  messages: [
                    { role: "user", content: prompt }
                  ]
                })
              });

              const data = await response.json();
              setSummary(data.content[0].text);
            } catch (error) {
              console.error('Errore generazione riassunto:', error);
              setSummary('Errore nella generazione del riassunto. Riprova piÃ¹ tardi.');
            } finally {
              setIsGeneratingSummary(false);
            }
          };

          // Cambia lingua e riavvia riconoscimento se attivo
          const changeLanguage = (newLang) => {
            setLanguage(newLang);
            if (isRecording && recognitionRef.current) {
              recognitionRef.current.stop();
              setTimeout(() => {
                recognitionRef.current.lang = newLang;
                recognitionRef.current.start();
              }, 100);
            }
          };

          // Esporta trascrizione
          const exportTranscript = () => {
            const exportData = {
              meetingFormat: meetingFormats[meetingFormat],
              timestamp: new Date().toLocaleString('it-IT'),
              transcript: transcript,
              notes: notes,
              summary: summary
            };
            
            const blob = new Blob([JSON.stringify(exportData, null, 2)], { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `meeting-transcript-${Date.now()}.json`;
            a.click();
            URL.revokeObjectURL(url);
          };

          // Copia trascrizione
          const copyTranscript = () => {
            const text = transcript.map(t => `${t.speaker} (${t.timestamp}): ${t.text}`).join('\n');
            navigator.clipboard.writeText(text);
          };

          return (
            <div className="min-h-screen bg-gray-50 p-4">
              <div className="max-w-6xl mx-auto">
                {/* Header */}
                <div className="bg-white rounded-lg shadow-sm border p-6 mb-6">
                  <div className="flex items-center justify-between mb-4">
                    <div>
                      <h1 className="text-2xl font-bold text-gray-900">AI Meeting Notes</h1>
                      <p className="text-gray-600">Trascrizione automatica in tempo reale</p>
                    </div>
                    <div className="flex items-center gap-4">
                      <select 
                        value={meetingFormat} 
                        onChange={(e) => setMeetingFormat(e.target.value)}
                        className="border rounded-lg px-3 py-2 text-sm"
                      >
                        {Object.entries(meetingFormats).map(([key, label]) => (
                          <option key={key} value={key}>{label}</option>
                        ))}
                      </select>
                      <select 
                        value={language} 
                        onChange={(e) => changeLanguage(e.target.value)}
                        className="border rounded-lg px-3 py-2 text-sm"
                      >
                        {Object.entries(languages).map(([key, label]) => (
                          <option key={key} value={key}>{label}</option>
                        ))}
                      </select>
                    </div>
                  </div>
                  
                  {/* Controlli Recording */}
                  <div className="flex items-center justify-between">
                    <div className="flex items-center gap-4">
                      <button
                        onClick={toggleRecording}
                        className={`flex items-center gap-2 px-6 py-3 rounded-lg font-medium transition-all ${
                          isRecording 
                            ? 'bg-red-500 hover:bg-red-600 text-white animate-pulse' 
                            : 'bg-blue-500 hover:bg-blue-600 text-white'
                        }`}
                      >
                        {isRecording ? React.createElement(MicOff, {size: 20}) : React.createElement(Mic, {size: 20})}
                        {isRecording ? 'Stop Recording' : 'Start Recording'}
                      </button>
                      
                      {isRecording && (
                        <div className="flex items-center gap-2 text-red-600">
                          <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
                          <span className="text-sm font-medium">Recording in corso...</span>
                        </div>
                      )}
                    </div>
                    
                    <div className="flex items-center gap-2">
                      {React.createElement(Users, {size: 16})}
                      <span className="text-sm text-gray-600">Speaker: {currentSpeaker}</span>
                      <button
                        onClick={() => setSpeakerCount(prev => prev + 1)}
                        className="text-sm text-blue-600 hover:text-blue-800"
                      >
                        +Add Speaker
                      </button>
                    </div>
                  </div>
                </div>

                {/* Tabs */}
                <div className="bg-white rounded-lg shadow-sm border">
                  <div className="border-b">
                    <nav className="flex">
                      <button
                        onClick={() => setActiveTab('transcript')}
                        className={`flex items-center gap-2 px-6 py-4 text-sm font-medium border-b-2 transition-colors ${
                          activeTab === 'transcript' 
                            ? 'border-blue-500 text-blue-600' 
                            : 'border-transparent text-gray-500 hover:text-gray-700'
                        }`}
                      >
                        {React.createElement(FileText, {size: 16})}
                        Trascrizione ({transcript.length})
                      </button>
                      <button
                        onClick={() => setActiveTab('notes')}
                        className={`flex items-center gap-2 px-6 py-4 text-sm font-medium border-b-2 transition-colors ${
                          activeTab === 'notes' 
                            ? 'border-blue-500 text-blue-600' 
                            : 'border-transparent text-gray-500 hover:text-gray-700'
                        }`}
                      >
                        {React.createElement(Users, {size: 16})}
                        Note Collaborative
                      </button>
                      <button
                        onClick={() => setActiveTab('summary')}
                        className={`flex items-center gap-2 px-6 py-4 text-sm font-medium border-b-2 transition-colors ${
                          activeTab === 'summary' 
                            ? 'border-blue-500 text-blue-600' 
                            : 'border-transparent text-gray-500 hover:text-gray-700'
                        }`}
                      >
                        {React.createElement(Brain, {size: 16})}
                        AI Summary
                      </button>
                    </nav>
                    
                    {/* Actions */}
                    <div className="flex items-center gap-2 px-6 py-3 bg-gray-50 border-t">
                      <button
                        onClick={copyTranscript}
                        className="flex items-center gap-1 px-3 py-1 text-sm text-gray-600 hover:text-gray-800"
                      >
                        {React.createElement(Copy, {size: 14})}
                        Copia
                      </button>
                      <button
                        onClick={exportTranscript}
                        className="flex items-center gap-1 px-3 py-1 text-sm text-gray-600 hover:text-gray-800"
                      >
                        {React.createElement(Download, {size: 14})}
                        Esporta
                      </button>
                      <button
                        onClick={generateSummary}
                        disabled={transcript.length === 0 || isGeneratingSummary}
                        className="flex items-center gap-1 px-3 py-1 text-sm bg-blue-500 text-white rounded hover:bg-blue-600 disabled:opacity-50"
                      >
                        {React.createElement(Brain, {size: 14})}
                        {isGeneratingSummary ? 'Generando...' : 'Rigenera Summary'}
                      </button>
                    </div>
                  </div>

                  {/* Content */}
                  <div className="p-6">
                    {activeTab === 'transcript' && (
                      <div className="space-y-4">
                        {transcript.length === 0 ? (
                          <div className="text-center py-12 text-gray-500">
                            {React.createElement(Mic, {size: 48, className: "mx-auto mb-4 opacity-50"})}
                            <p>Avvia la registrazione per iniziare la trascrizione automatica</p>
                            <p className="text-sm mt-2">Supporta italiano e inglese con riconoscimento automatico</p>
                          </div>
                        ) : (
                          <div className="space-y-3 max-h-96 overflow-y-auto">
                            {transcript.map((entry) => (
                              <div key={entry.id} className="flex gap-3 p-3 bg-gray-50 rounded-lg">
                                <div className="flex-shrink-0">
                                  <div className="w-8 h-8 bg-blue-500 rounded-full flex items-center justify-center text-white text-xs font-medium">
                                    {entry.speaker.charAt(entry.speaker.length - 1)}
                                  </div>
                                </div>
                                <div className="flex-grow">
                                  <div className="flex items-center gap-2 mb-1">
                                    <span className="font-medium text-sm text-gray-900">{entry.speaker}</span>
                                    <span className="text-xs text-gray-500">{entry.timestamp}</span>
                                    <span className="text-xs px-2 py-1 bg-gray-200 rounded text-gray-600">
                                      {entry.language}
                                    </span>
                                  </div>
                                  <p className="text-gray-800">{entry.text}</p>
                                </div>
                              </div>
                            ))}
                          </div>
                        )}
                      </div>
                    )}

                    {activeTab === 'notes' && (
                      <div>
                        <textarea
                          value={notes}
                          onChange={(e) => setNotes(e.target.value)}
                          placeholder={`Aggiungi note collaborative durante il meeting...
                          
â¢ Usa @mentions per taggare i colleghi
â¢ Evidenzia punti importanti
â¢ Scrivi domande o commenti
â¢ Queste note verranno integrate nel summary AI`}
                          className="w-full h-64 p-4 border rounded-lg resize-none focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
                        />
                        <div className="mt-4 text-sm text-gray-600">
                          <p><strong>Tip:</strong> Le note collaborative vengono utilizzate dall'AI per creare summary piÃ¹ accurati e personalizzati.</p>
                        </div>
                      </div>
                    )}

                    {activeTab === 'summary' && (
                      <div>
                        {summary ? (
                          <div className="prose max-w-none">
                            <div className="bg-blue-50 border-l-4 border-blue-500 p-4 mb-6">
                              <h3 className="text-lg font-semibold text-blue-900 mb-2">
                                Summary AI - {meetingFormats[meetingFormat]}
                              </h3>
                              <p className="text-blue-700 text-sm">
                                Generato automaticamente dalla trascrizione e dalle note collaborative
                              </p>
                            </div>
                            <div className="whitespace-pre-wrap text-gray-800 leading-relaxed">
                              {summary}
                            </div>
                          </div>
                        ) : (
                          <div className="text-center py-12 text-gray-500">
                            {React.createElement(Brain, {size: 48, className: "mx-auto mb-4 opacity-50"})}
                            <p>Il summary AI verrÃ  generato automaticamente alla fine del meeting</p>
                            <p className="text-sm mt-2">Oppure clicca "Rigenera Summary" per crearlo ora</p>
                            {isGeneratingSummary && (
                              <div className="mt-4">
                                <div className="animate-spin w-6 h-6 border-2 border-blue-500 border-t-transparent rounded-full mx-auto"></div>
                                <p className="text-sm mt-2">Generazione in corso...</p>
                              </div>
                            )}
                          </div>
                        )}
                      </div>
                    )}
                  </div>
                </div>

                {/* Info Footer */}
                <div className="mt-6 text-center text-sm text-gray-500">
                  <p>ð¤ Utilizza le cuffie per una migliore qualitÃ  audio â¢ ð Riconoscimento automatico IT/EN â¢ ð¤ Summary AI powered by Claude</p>
                </div>
              </div>
            </div>
          );
        };

        ReactDOM.render(<LiveTranscriptionTool />, document.getElementById('root'));
    </script>
</body>
</html>
